{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e88fa1b",
   "metadata": {},
   "source": [
    "# Assignment 1: Semantic Clustering of Paintings\n",
    "\n",
    "## Due: 2025-02-28\n",
    "\n",
    "In the [github repository](https://github.com/erdmann/MVA_2025) there is a data folder containing metadata and CC0 images for paintings in the Rijksmuseum with aspect ratios between 0.5 and 2.0.  They are named according to the inventory number in the Rijksmuseum numbering scheme.\n",
    "\n",
    "The goal of this assignment is to use a pre-trained convolutional neural network with the final classification head removed to generate semantic embedding vectors for each painting and to organize them according to similarity.  An online zoomable example of an approximate organization of 177k works on paper from the Rijksmuseum can be found here [Erdmann, 2016](http://dev.erdmann.io/viewer.html?iip=false&prefix=/Rijksmuseum/&mode=sync&pointer=0.094,0.000&i=rijksmuseum_rp_grid_02)\n",
    "\n",
    "## IMPORTANT: rename your .ipynb notebook to contain your family name somewhere prior to submission.  \n",
    "\n",
    "Submission details will be given at the start of the next meeting on February 28."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f51d70",
   "metadata": {},
   "source": [
    "## Name:\n",
    "## Student ID:\n",
    "## Date:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad1377f",
   "metadata": {},
   "source": [
    "## Part 1: make a database of embeddings\n",
    "\n",
    "There are several pre-trained networks available in pytorch and elsewhere.  These include Alexnet VGG13, VGG16, VGG19, Resnet34, Resnet50, and so on.  In general, they have a feature generation stage built with layers of convolutional filters followed by a series of fully-connected (MLP) layers ending in a 1000-dimensional vector, corresponding with the original training on ImageNet1k.  Load a pre-trained network (Resnets perform well, but it's your choice) and make a new network that is missing the final projection to 1000 dimensions.  For each of the images in the Rijksmuseum paintings folder, make a pipeline that downsamples the image to 224px minimum dimension, center-crops it to make a 224x224 image, and run the network in inference mode (no gradient accumulation) to make a database of high-dimensional 1D semantic embeddings, one per image.\n",
    "\n",
    "Show all your code.  Indicate where you have used AI to assist you where approproate.  Comment the code, but only give comments where they are useful and non-obvious.\n",
    "\n",
    "Be sure to account for the image value normalization required by the pretrained network (typically to ImageNet1k stats) in your data pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1f347a",
   "metadata": {},
   "source": [
    "## Part 2: TSNE or Umap dimension reduction\n",
    "\n",
    "Use a modern nonlinear dimension reduction algorithm such as TSNE or Umap to reduce the collection of high-dimensional embeddings to a 2D point cloud in which images with similar embeddings will appear near each other.  Use a cosine similarity metric, i.e., explicitly or implicitly normalize each embedding to unit length and measure similarity according to the inner product.  Make an attractive scatter plot of the results with simple points.  Color the points according to some interesting criterion, such as the date of the painting as extracted from the metadata JSON file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938d967a",
   "metadata": {},
   "source": [
    "## Part 3: Converting the point cloud to a regular grid\n",
    "\n",
    "The number of images is such that they will fit evenly into a 69 column x 68 row grid.  Create or develop any exact or approximate algorithm, such as the Hungarian algorithm or optimal transport to solve the \"assignment problem\" of placing the images into a grid such that they closely mimic the relative arrangement of points in the point cloud from Part 2.\n",
    "\n",
    "What metric are you using to judge the quality of the mapping?\n",
    "\n",
    "n.b. Beware of the $\\mathrm O(n^3)$ of the Hungarian algorithm since $n$ is large here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3818d03a",
   "metadata": {},
   "source": [
    "## Part 4: Create a single large grid image\n",
    "\n",
    "Given the grid arrangement from Part 3, use `np.memmap` or `pyvips.arrayjoin([list of pyvips.Image])` or the CLI version with `vips arrayjoin \"list of filenames with one set of quotes around the entire list\"` to create a single massive 69-column, 68-row image from 400x400 center-cropped images of each of the painting images arranged according to your solution from Part 3.  Save the image as a single JPEG file.  View the image using nip2 to explore it.\n",
    "\n",
    "Show your code or CLI session here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d04383",
   "metadata": {},
   "source": [
    "Insert images from regions showing evidence that the method is doing semantic clustering and not just pixel similarity clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c457c6",
   "metadata": {},
   "source": [
    "Using the `vipsthumbnail` CLI tool or its equivalent in pyvips, make a downsized version of your grid image with maximum dimensions of around 3000 pixels in JPEG format.  Insert the image here along with the code or CLI command you ran to create it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a08aa1e",
   "metadata": {},
   "source": [
    "What are your overall observations about the efficacy of this method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b346b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
